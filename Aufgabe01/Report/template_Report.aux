\relax 
\@writefile{toc}{\contentsline {section}{\numberline {0.1}Einfaches Perceptron - Datengeneration}{1}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Iteration distribution over gamma}}{1}}
\newlabel{tab:DataSets}{{1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {0.2}Einfaches Perceptron - Perceptrontraining}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.2.1}Anzahl Iterationen}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.2.2}Welchen Einflu{\ss } hat die Schrittweite}{1}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Iteration distribution over gamma}}{2}}
\newlabel{tab:GammaToIterations}{{2}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.2.3}Daten und Entscheidungsgrenzen im $\mathbb  {R}^2$}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.2.4}Wie ist das Verhalten bei nicht linear separierbaren Daten}{2}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Iteration distribution over gamma}}{3}}
\newlabel{tab:DataSetsAndBounds}{{3}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {0.3}Lineare Regression}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.3.1}Gewichtsvektor mittels Gradientenabstieg bei quadratischer Fehlerfunktion}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.3.2}Optimaler Gewichtsvektor $w^*$}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.3.3}Konvergenzverhalten in Abh\"angigkeit von $\gamma $}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.3.4}Erwartungswert und Varianz von $w^*$ im Bezug zu Dimensionalit√§t $d$ von $f(x)$}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces variance and deviantion of $w^*$ over dimension}}{4}}
\newlabel{tab:VarianceAndDeviantion}{{4}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces overfitting of $y^*$ curves over dimension}}{5}}
\newlabel{tab:Overfitting}{{1}{5}}
