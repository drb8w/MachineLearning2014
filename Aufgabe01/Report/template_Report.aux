\relax 
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Einfaches Perceptron - Datengeneration}{1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Einfaches Perceptron - Perceptrontraining}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Anzahl Iterationen}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Welchen Einflu{\ss } hat die Schrittweite $\gamma $}{1}}
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces data sets of separatable data}}{2}}
\newlabel{tab:DataSets}{{1.1}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Daten und Entscheidungsgrenzen im $\mathbb  {R}^2$}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces iterations of online training for increasing margins}}{3}}
\newlabel{fig:meanIterOverDataSets}{{1.1}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Wie ist das Verhalten bei nicht linear separierbaren Daten}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {1.2}{\ignorespaces iteration distribution over gamma}}{4}}
\newlabel{tab:GammaToIterations}{{1.2}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {1.3}{\ignorespaces data sets and decition boundaries}}{5}}
\newlabel{tab:DataSetsAndBounds}{{1.3}{5}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Lineare Regression}{6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Gewichtsvektor $w_{online}$ mittels Gradientenabstieg bei quadratischer Fehlerfunktion}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces online vs batch LMS}}{6}}
\newlabel{fig:onlineVsBatchLMS}{{2.1}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Optimaler Gewichtsvektor $w^*$}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Konvergenzverhalten in Abh\"angigkeit von Lernrate $\gamma $}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces convergence over gamma}}{7}}
\newlabel{fig:ConvergenceOverGamma}{{2.2}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces convergence over gamma beyond opmital region}}{8}}
\newlabel{fig:ConvergenceOverGammaWDiverge}{{2.3}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Erwartungswert und Varianz von $w^*$ im Bezug zu Dimensionalit\"at $d$ von $f(x)$}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces overfitting of $f_{w^*}(x)$ curves over dimension}}{8}}
\newlabel{fig:Overfitting}{{2.4}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Mittlere quadratische Abweichung von $f_{w^*}(x^*)$}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces mean error of $f_{w^*}(x^*)$ curves over dimension}}{9}}
\newlabel{fig:MeanError}{{2.5}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Gewichtsvektor $w^*$ bei ungest\"orter Trainingsmenge \"uber Dimension $d$}{9}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces variance, deviantion and mean of $w^*$ coefficient over dimension}}{10}}
\newlabel{tab:VarianceAndDeviantion}{{2.1}{10}}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces $f_{w^*}(x)$ over dimension}}{11}}
\newlabel{tab:f_x_overDimension}{{2.2}{11}}
